{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from PIL import Image\n",
    "import scipy.io\n",
    "import scipy.misc\n",
    "import matplotlib.pyplot as plt\n",
    "import skimage\n",
    "from tensorflow import keras\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.applications.VGG16(weights = 'imagenet', include_top = False, input_shape=(224,224,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: DeprecationWarning: `imread` is deprecated!\n",
      "`imread` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``imageio.imread`` instead.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:105: UserWarning: The default mode, 'constant', will be changed to 'reflect' in skimage 0.15.\n",
      "  warn(\"The default mode, 'constant', will be changed to 'reflect' in \"\n",
      "C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: DeprecationWarning: `imread` is deprecated!\n",
      "`imread` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``imageio.imread`` instead.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "content_image = scipy.misc.imread('content.png')\n",
    "content_image = skimage.transform.resize(content_image, (224,224,3))\n",
    "style_image = scipy.misc.imread('style.png')\n",
    "style_image = skimage.transform.resize(style_image, (224,224,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_content_cost(a_C, a_G):\n",
    "    m,nh,nw,nc = a_G.get_shape().as_list()\n",
    "    a_Cu = tf.reshape(a_C,[nc, nh*nw])\n",
    "    a_Gu = tf.reshape(a_G, [nc, nh*nw])\n",
    "    \n",
    "    return tf.reduce_sum(tf.square(tf.subtract(a_Gu, a_Cu)))*(1/4*nc*nw*nh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gram_matrix(a):\n",
    "    \n",
    "    return tf.matmul(a, tf.transpose(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computer_style_layer_cost(a_S, a_G):\n",
    "    \n",
    "    m,nh,nw,nc = a_G.get_shape().as_list()\n",
    "    a_Su = tf.reshape(a_S,[nc, nh*nw])\n",
    "    a_Gu = tf.reshape(a_G, [nc, nh*nw])\n",
    "    \n",
    "    GS = gram_matrix(a_Su)\n",
    "    GG = gram_matrix(a_Gu)\n",
    "    \n",
    "    return (tf.reduce_sum(tf.square(tf.subtract(GS, GG))))*(1/4*(nc*nh*nw)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computer_style_cost(model, sess, a_G, STYLE_LAYERS, style_image):\n",
    "    \n",
    "    J_style = 0\n",
    "    \n",
    "    for layer_name, coeff in STYLE_LAYERS:\n",
    "        out = model.get_layer(layer_name).output\n",
    "        \n",
    "        a_S = sess.run(out, feed_dict = {model.layers[0].input: style_image})\n",
    "        a_G = out\n",
    "        \n",
    "        J_style_layer  = computer_style_layer_cost(a_S, a_G)\n",
    "        \n",
    "        J_style += coeff*J_style_layer\n",
    "        \n",
    "    return J_style"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "style_image = style_image.reshape(-1,224,224,3)\n",
    "content_image = content_image.reshape(-1, 224, 224, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def total_cost(J_content, J_style, alpha = 10, beta = 40):\n",
    "    \n",
    "    return (J_content*alpha+J_style*beta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py:1702: UserWarning: An interactive session is already active. This can cause out-of-memory errors in some cases. You must explicitly call `InteractiveSession.close()` to release resources held by the other session(s).\n",
      "  warnings.warn('An interactive session is already active. This can '\n"
     ]
    }
   ],
   "source": [
    "sess = tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "STYLE_LAYERS = [\n",
    "    ('block1_conv1', 0.2),\n",
    "    ('block2_conv1', 0.2),\n",
    "    ('block3_conv1', 0.2),\n",
    "    ('block4_conv1', 0.2),\n",
    "    ('block5_conv1', 0.2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 224, 224, 3)       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
      "=================================================================\n",
      "Total params: 14,714,688\n",
      "Trainable params: 0\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset the graph\n",
    "tf.reset_default_graph()\n",
    "\n",
    "# Start interactive session\n",
    "sess = tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.applications.VGG16(weights = 'imagenet', include_top = False, input_shape=(224,224,3))\n",
    "out = model.get_layer('block2_conv2').output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_C = sess.run(out, {model.layers[0].input:content_image})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_G = out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "J_content= compute_content_cost(a_C,a_G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'mul:0' shape=() dtype=float32>"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "J_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "J_style = computer_style_cost(model, sess, a_G, STYLE_LAYERS, style_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'add_4:0' shape=() dtype=float32>"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "J_style"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "J_total  = total_cost(J_content, J_style)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define optimizer (1 line)\n",
    "optimizer = tf.train.AdamOptimizer(2.0)\n",
    "\n",
    "# define train_step (1 line)\n",
    "train_step = optimizer.minimize(J_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_nn(sess, input_image, num_iterations = 10):\n",
    "    \n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    generated_image = sess.run(model.input, {model.layers[0].input:input_image})\n",
    "    \n",
    "    for i in range(num_iterations):\n",
    "        \n",
    "        sess.run(train_step, {model.layers[0].input:generated_image})\n",
    "        \n",
    "        generated_image = model.layers[1].eval()\n",
    "        \n",
    "    \n",
    "    return generated_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_image = np.random.randn(1,224,224,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'input_1:0' shape=(?, 224, 224, 3) dtype=float32>"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers[1].input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "generated_image = sess.run(model.input, {model.layers[0].input:input_image})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[ 0.46884185,  2.232418  ,  0.303477  ],\n",
       "         [-1.5241139 ,  0.20254155, -0.17619936],\n",
       "         [ 1.3210721 ,  1.532633  ,  0.63175404],\n",
       "         ...,\n",
       "         [-0.7752622 ,  0.34948277, -1.229326  ],\n",
       "         [ 0.7068119 ,  1.0432702 ,  0.09425525],\n",
       "         [ 0.7391177 , -0.80449593, -0.261397  ]],\n",
       "\n",
       "        [[ 1.5157132 , -1.8960536 , -0.7503247 ],\n",
       "         [-0.20462036, -1.1640986 ,  0.02248379],\n",
       "         [-0.6468506 ,  1.1100645 , -0.5297825 ],\n",
       "         ...,\n",
       "         [-0.7831245 , -0.6102612 ,  0.24752188],\n",
       "         [-0.56931436, -1.4574596 , -1.6423726 ],\n",
       "         [-0.51166046,  1.1575136 ,  0.6784497 ]],\n",
       "\n",
       "        [[-2.1179256 , -0.89244205, -0.4490084 ],\n",
       "         [ 0.05243364, -0.50236017, -0.01310203],\n",
       "         [ 0.79176676,  0.9050835 ,  0.02113134],\n",
       "         ...,\n",
       "         [ 0.77650404, -1.2987448 ,  1.1164126 ],\n",
       "         [ 1.2549706 ,  0.50496906, -0.11764778],\n",
       "         [-0.86830926,  0.04294144, -0.56626654]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[-0.79386723,  0.8181863 ,  1.6958797 ],\n",
       "         [-0.7133415 ,  0.3359176 ,  0.49035808],\n",
       "         [ 0.72154534,  0.9479687 ,  0.8433981 ],\n",
       "         ...,\n",
       "         [-0.1050244 , -0.2850778 , -0.6221783 ],\n",
       "         [-0.7360548 ,  0.0276901 ,  0.67586976],\n",
       "         [ 0.1878462 ,  1.025278  , -1.3333505 ]],\n",
       "\n",
       "        [[-0.14518201, -0.497008  ,  1.5730014 ],\n",
       "         [ 0.8029865 ,  0.96885234, -0.555263  ],\n",
       "         [ 1.6068169 , -2.5621097 ,  0.10940538],\n",
       "         ...,\n",
       "         [-1.4398228 , -1.9427799 , -0.32198077],\n",
       "         [-0.97090435, -1.4254055 ,  1.7346512 ],\n",
       "         [-0.04303468,  2.8156745 , -0.40288994]],\n",
       "\n",
       "        [[-0.4958677 , -0.43581316, -0.5068711 ],\n",
       "         [ 1.9184175 , -1.2288194 ,  2.4088387 ],\n",
       "         [-0.03780036, -0.92898774,  0.51055163],\n",
       "         ...,\n",
       "         [-0.64255184,  2.0001452 ,  0.24358349],\n",
       "         [ 0.19797002,  0.10413335, -0.3780541 ],\n",
       "         [ 0.86885756, -0.48744148, -0.43927503]]]], dtype=float32)"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generated_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Conv2D' object has no attribute 'eval'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-162-4e295414a92e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel_nn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msess\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_image\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-157-24935f4302ba>\u001b[0m in \u001b[0;36mmodel_nn\u001b[1;34m(sess, input_image, num_iterations)\u001b[0m\n\u001b[0;32m      9\u001b[0m         \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_step\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m{\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mgenerated_image\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m         \u001b[0mgenerated_image\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'Conv2D' object has no attribute 'eval'"
     ]
    }
   ],
   "source": [
    "img = model_nn(sess, input_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(img[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
